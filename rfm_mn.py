# -*- coding: utf-8 -*-
"""RFM.MN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NgCwZLo546xoyxKhxmxZZChz1m2u8IOb

dataset link: https://www.kaggle.com/datasets/ddosad/auto-sales-data

# RFM ANALYSIS

RFM analysis is a marketing tool used to understand and segment your customers based on their purchasing habits. It stands for Recency, Frequency, and Monetary Value.

Recency: How recently a customer made a purchase.
Frequency: How often a customer makes purchases.
Monetary Value: How much money a customer spends with us.
By analyzing these factors, we can identify our most valuable customers, target them with relevant marketing campaigns, and predict future customer behavior.

This dataset provides detailed sales information for an automobile company. It includes data on individual orders (order number, date, status, etc.), along with information about the items purchased (quantity, price, product code, MSRP, product line). Customer details like name, address, and contact information are also included. Additionally, the dataset offers insights into customer behavior with columns like "days since last order" and "deal size"
"""

from google.colab import drive
drive.mount('/content/gdrive')

#Import the Libraries
import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px

from warnings import filterwarnings
filterwarnings('ignore')

df_raw = pd.read_csv('/content/gdrive/MyDrive/WebSocial-24/Auto Sales data.csv')

df_raw.head()

"""# EDA and data processing"""

df_raw.describe(percentiles=[.01,.1,.25,.5,.75,.90,.95,.99]).T #T for transpose

"""let's start by reducing the number of columns"""

#check type data
df_raw.info()

print(df_raw.isnull().sum()) #check missing values

"""there are no missing values"""

df_raw.drop(columns=['ADDRESSLINE1', 'STATUS', 'CONTACTFIRSTNAME', 'CONTACTLASTNAME', 'PHONE', 'ORDERLINENUMBER', 'POSTALCODE'], inplace=True) #drop columns

df_raw

"""Data Characteristics:
The dataset contains 2747 entries with 20 columns.
All columns have 2747 non-null values, hence no missing found
Key columns include sales transaction details, customer information, product details, order status, and recency information.
Data types vary across columns, including floats, datetime, and objects.
"""

#Changes type data in column Order_date
df_raw['ORDERDATE'] = pd.to_datetime(df_raw['ORDERDATE'])
df_raw.info()

#check transaction's timestamps
df_raw['ORDERDATE'].max()

df_raw['ORDERDATE'].min()

# Define helper functions
def convert_to_datetime(df_raw, col_name):
  df_raw[col_name] = pd.to_datetime(df_raw[col_name])

def calculate_daily_sales(df_raw):
  df_raw['ORDERDATE'] = df_raw['ORDERDATE'].dt.date
  return df_raw.groupby('ORDERDATE')['ORDERNUMBER'].sum()

def calculate_monthly_sales(df_raw):
  return df_raw.resample('M', on='ORDERDATE')['ORDERNUMBER'].sum()

# Process data
convert_to_datetime(df_raw, 'ORDERDATE')
df = calculate_daily_sales(df_raw.copy())
df_monthly = calculate_monthly_sales(df_raw.copy())

# Prepare plot
plt.figure(figsize=(21, 9))
plt.style.use('fivethirtyeight')
ax = plt.gca()

# Plot monthly sales
sns.lineplot(data=df_monthly.reset_index(), x='ORDERDATE', y='ORDERNUMBER', ax=ax, label='Monthly Sales', linewidth=2)

# Set plot limits
plt.xlim(pd.Timestamp('2018-01-01'), pd.Timestamp('2020-07-31'))

# Define Christmas Day dates
christmas_days = ['2018-12-25', '2019-12-25']
christmas_days = pd.to_datetime(christmas_days)

# Vertical lines for Christmas Days
for christmas_day in christmas_days:
  plt.axvline(x=christmas_day, color='red', linestyle='--', label='Christmas Day')

# Define Black Friday dates
black_fridays = ['2018-11-23', '2019-11-29']
black_fridays = pd.to_datetime(black_fridays)

# Vertical lines for Black Friday
for black_friday in black_fridays:
  plt.axvline(x=black_friday, color='green', linestyle='--', label='Black Friday')

plt.tight_layout()
plt.grid(True, axis='x', linestyle='--', alpha=0.5)
plt.legend()
plt.show()

"""from this graph we can see spikes in sales in the times between the months of october and january of both year, assuming the majority of sales are done around christmas holiday time, however we can see that in 2019 the date coincides with the Black Friday.

Analsys using RFM analyst methode
RFM itself stands for recency, frequency, and monetary value.

Recency indicates the time of the customer's last interaction with the product.
Frequency is about how often customers make purchases.
Monetary value measures the amount of money a customer spends on each purchase transaction.

## Country of customers
"""

df_raw.COUNTRY.nunique() #number of unique countries

colors = plt.cm.rainbow(np.linspace(0, 1, 25))

# Calculate the count of unique costumers from the same country
customer_counts = df_raw.groupby('COUNTRY')['CUSTOMERNAME'].nunique()
# Sort by descending customer count
sorted_counts = customer_counts.sort_values(ascending=False)

plt.figure(figsize=(30, 15))
ax = sorted_counts.plot(kind='bar', color=colors, edgecolor='black')

plt.style.use('ggplot')

plt.title('Number of customers from various countries', fontsize=27, fontweight='bold')
plt.xlabel('Countries', fontsize=25, fontweight='bold')
plt.ylabel('Number of customers', fontsize=25, fontweight='bold')

plt.xticks(rotation=90, ha='right', fontsize=20)
plt.yticks(fontsize=20)

plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)

ax.legend(['Number of Customers'], fontsize=20, frameon=True, shadow=True, borderpad=1)

plt.tight_layout()
plt.show()

#Number of orders from different countries
colors = plt.cm.rainbow(np.linspace(0, 1, 25))

country_counts = df_raw['COUNTRY'].value_counts()
country_counts = country_counts.sort_values(ascending=False)
plt.figure(figsize=(30, 15))
ax = country_counts.plot(kind='bar', color= colors, edgecolor='black')

plt.style.use('ggplot')

plt.title('Number of orders form various country', fontsize=27, fontweight='bold')
plt.xlabel('Countries', fontsize=25, fontweight='bold')
plt.ylabel('Number of sales', fontsize=25, fontweight='bold')

plt.xticks(rotation=90, ha='right', fontsize=20)
plt.yticks(fontsize=20)

plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)

ax.legend(['Products Sold'], fontsize=20, frameon=True, shadow=True, borderpad=1)

plt.tight_layout()
plt.show()

"""the countries who have the most clients seem to follow the trend of the ones with most orders.

## Size of the deals
"""

plt.pie(df_raw["DEALSIZE"].value_counts(),
        labels=df_raw["DEALSIZE"].unique(),
        autopct="%.2f",
        explode=[0.01,0,0.3],
        shadow=True)
plt.title("Ratio of the Dealsize")
plt.show()

"""## Graphs"""

#Most and least bought product
frequency = df_raw['PRODUCTCODE'].value_counts()

most_frequent = frequency.idxmax()
most_frequent_count = frequency.max()

least_frequent = frequency.idxmin()
least_frequent_count = frequency.min()

print(f'The most frequently sold product is: {most_frequent}, sold {most_frequent_count} times.')
print(f'The least frequently sold product is: {least_frequent}, sold {least_frequent_count} times.')

df_raw.CUSTOMERNAME.nunique()

df_raw.PRODUCTCODE.nunique()

# Average Number of Invoice per Customer
df_raw.groupby('CUSTOMERNAME').agg(PRODUCTCODE=('PRODUCTCODE', 'nunique')).PRODUCTCODE.mean()

#top 10 most sold products
products_counts = df_raw.groupby('PRODUCTLINE')['PRODUCTCODE'].value_counts()
top_products = products_counts.head(10)

plt.figure(figsize=(20, 8))
ax = top_products.plot(kind='bar', color='maroon', edgecolor='black')

plt.style.use('ggplot')

plt.title('Top 10 Most Sold Products', fontsize=16, fontweight='bold')
plt.xlabel('Product', fontsize=12, fontweight='bold')
plt.ylabel('Products Sold', fontsize=12, fontweight='bold')

plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(fontsize=10)

plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)

ax.legend(['Products Sold'], fontsize=10, frameon=True, shadow=True, borderpad=1)

plt.tight_layout()
plt.show()
print(top_products)

"""from this graph we can clearly state that the most popular productline among customers is Classic Cars seen as all the 10 most sold items are part of this category.

# RFM
"""

# grouping the dataset
transaction_df = df_raw.groupby('CUSTOMERNAME').agg(ORDERNUMBER=('ORDERNUMBER', 'nunique')).reset_index()
revenue_df = df_raw.groupby('CUSTOMERNAME').agg(SALES=('SALES', 'sum')).reset_index()
quantity_df = df_raw.groupby('CUSTOMERNAME').agg(QUANTITYORDERED=('QUANTITYORDERED', 'sum')).reset_index()

# merging the datasets
merge_df = transaction_df.merge(revenue_df, on='CUSTOMERNAME')
merge_df = merge_df.merge(quantity_df, on='CUSTOMERNAME')

merge_df

"""##Creating the dataframes"""

# customers
df_customers = merge_df['CUSTOMERNAME']

# Recency
def calculate_recency(data):
  MaxInvoiceDate = pd.to_datetime('31/05/2020')


  recency_data = df_raw.groupby('CUSTOMERNAME')['ORDERDATE'].max()
  recency_data = recency_data.apply(lambda x: (MaxInvoiceDate - x).days)
  recency_data.name = 'Recency'
  return recency_data.reset_index()  # Combine customer IDs with recency

# Example usage
df_recency = calculate_recency(df)

# Monetary
df_monetary = df_raw.groupby('CUSTOMERNAME').agg(Monetary=('SALES', 'sum')).reset_index()

# Frequency
df_frequency = df_raw.groupby('CUSTOMERNAME').agg(Frequency=('SALES', 'nunique')).reset_index()

df_rfm = pd.merge(df_customers, df_recency, on='CUSTOMERNAME', how='left')
df_rfm = pd.merge(df_rfm, df_monetary, on='CUSTOMERNAME', how='left')
df_rfm = pd.merge(df_rfm, df_frequency, on='CUSTOMERNAME', how='left')

df_rfm

"""filter outliers"""

df_rfm[['Recency','Frequency','Monetary']].describe(percentiles=[.01,.1,.25,.5,.75,.90,.95,.99]).T

df_rfm_clean = df_rfm.copy()

df_rfm_clean = df_rfm_clean[df_rfm_clean['Frequency'] <= 46]
df_rfm_clean = df_rfm_clean[df_rfm_clean['Frequency'] > 1]
df_rfm_clean = df_rfm_clean[df_rfm_clean['Monetary'] <= 154758]

corr_matrix = df_rfm_clean[['Recency','Frequency','Monetary']].corr()
corr_matrix
# Plot correlation heatmap
plt.figure(figsize=(21, 9))
plt.style.use('fivethirtyeight')
sns.heatmap(corr_matrix, annot=True)
plt.title('Correlation Heatmap')
plt.show()

#correlation between frequency and monetary
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Frequency', y='Monetary', data=df_rfm_clean)
plt.xlabel('Frequency')
plt.ylabel('Monetary')
plt.title('Correlation between Frequency and Monetary')
plt.show()

"""## Score distribution"""

# ranking the scores
df_rfm_clean['R_rank'] = df_rfm_clean['Recency'].rank(ascending=False)
df_rfm_clean['F_rank'] = df_rfm_clean['Frequency'].rank(ascending=True)
df_rfm_clean['M_rank'] = df_rfm_clean['Monetary'].rank(ascending=True)

# normalizing the rank of the customers
df_rfm_clean['R_rank_norm'] = (df_rfm_clean['R_rank']/df_rfm_clean['R_rank'].max())*100
df_rfm_clean['F_rank_norm'] = (df_rfm_clean['F_rank']/df_rfm_clean['F_rank'].max())*100
df_rfm_clean['M_rank_norm'] = (df_rfm_clean['F_rank']/df_rfm_clean['M_rank'].max())*100

df_rfm_clean.drop(columns=['R_rank', 'F_rank', 'M_rank'], inplace=True)

df_rfm_clean.head()

RECENCY_WEIGHT = .4
FREQUENCY_WEIGHT = .3
MONETARY_WEIGHT = .3



df_rfm_clean['RFMScore'] = (
    RECENCY_WEIGHT * df_rfm_clean['R_rank_norm'] +
    FREQUENCY_WEIGHT * df_rfm_clean['F_rank_norm'] +
    MONETARY_WEIGHT * df_rfm_clean['M_rank_norm'])

df_rfm_clean[['RFMScore']].describe(percentiles=[.01,.1,.25,.5,.75,.90,.95,.99]).T

plt.figure(figsize=(21, 9))
plt.style.use('fivethirtyeight')
sns.histplot(df_rfm_clean, x='RFMScore', bins=100)
plt.xlabel('RFM Score')
plt.ylabel('Number of Customers')
plt.title('Distribution plot of RFM Score')
plt.show()

"""### Evaluation of the costumer"""

df_rfm_clean["RFMSegment"] = np.where(
    df_rfm_clean['RFMScore'] > 85, "4. Elite Customer",
        np.where(df_rfm_clean['RFMScore'] > 70, "3. High value Customer",
            np.where(df_rfm_clean['RFMScore'] > 30, "2. Medium value Customer", "1. Low value Customer")))

#Customer categories defined
df_rfm_clean = df_rfm_clean.sort_values(by='RFMSegment')

plt.figure(figsize=(21, 9))
plt.style.use('fivethirtyeight')
sns.histplot(x='RFMSegment', data=df_rfm_clean)
plt.xlabel('Frequency')
plt.ylabel('Recency')
plt.title('Customer categories')
plt.show()

df_rfm_clean.groupby("RFMSegment").CUSTOMERNAME.count() #number of customers in each category

(
    df_rfm_clean
    .groupby("RFMSegment")
    .agg(
        avg_recency=("Recency", "mean")
        , avg_frequency=("Frequency", "mean")
        , avg_monetary=("Monetary", "mean")
    )
) #average values of each category

"""# Descriptive Summary of the dataset - Numeric features"""

display(round(df_raw.describe(),2).T)

df_raw.select_dtypes(include = ['object']).describe().T #object features

"""Sales Amount: The average sales amount per transaction is approximately 3,553. Customers make purchases ranging from '482.13' to '14,082.80.'
Quantity Ordered On average, customers order approximately 35 items per transaction, with a minimum of 6 and a maximum of 97 items.
Price Each The average price of each item in an order is approximately 101. Prices vary between a minimum of 26.88 and a maximum of 252.87.
Manufacturer's Suggested Retail Price (MSRP The average MSRP is approximately 00.69, with prices ranging from 33 to 214.Customer Concentration "Euro Shopping Channel" is the top customer, with 259 transactions.
Geographic Trends "Madrid" and "USA" are the most frequent city and country, respectively.
Deal Sizes The majority of deals fall into the "Medium" category, accounting for 1349 cases.
"""